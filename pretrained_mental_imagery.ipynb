{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook - fast calibration in BCI with deep learning\n",
    "\n",
    "This notebook is designed as a tutorial and is composed of two independent parts. The first one is focused on (pre-)training neural networks for EEG decoding. In this part, you will see how you can select a neural network architecture from Braindecode, train it and share the resulting pre-trained network on the HuggingFace Hub. The second part is focused on re-using pre-trained models. There, you will learn how you can download pre-trained models from the HuggingFace Hub, fine-tune them or use them in scikit-learn pipelines and finally, benchmark them on BCI datasets with MOABB. These two parts are ment to be independent, so if you are only interested in re-using my pre-trained models, you can directly [jump to Part 2](#part-2---re-using-pre-trained-neural-networks).\n",
    "\n",
    "To run this notebook, you will need the following libraries installed in your python environment:\n",
    "- `numpy`\n",
    "- `torch`\n",
    "- `scikit-learn`\n",
    "- `skorch`\n",
    "- `braindecode`\n",
    "- `huggingface_hub`\n",
    "- `moabb`\n",
    "- (`notebook` / `jupyterlab`)\n",
    "\n",
    "\n",
    "## Part 1 -  (Pre-)Training neural networks\n",
    "\n",
    "This part is dedicated to pre-training neural networks. In this tutorial, we will use [PyTorch](https://pytorch.org) to implement and train those networks, but other deep learning frameworks exist such as [JAX](https://jax.readthedocs.io/en/latest/index.html) or [TensorFlow](https://www.tensorflow.org).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Braindecode architecture\n",
    "\n",
    "The first step to train a neural network is to define its architecture. Thankfully, some architectures have already been created and implemented so we will only have to select one. For this, we will use the [Braindecode](https://braindecode.org/) library in which many neural networks designed for EEG processing and BCI decoding have been implemented in Pytorch. In particular, we will use the [EEGNetv4](https://braindecode.org/stable/generated/braindecode.models.EEGNetv4.html) model introduced in [Lawhern et. al, 2018](https://doi.org/10.1088/1741-2552/aace8c) because it is rather light-weight, and it showed a good classification performance on various BCI paradigms.\n",
    "\n",
    "In this demo, we will use fake meaningless data that has 3 EEG channels, two different classes and 200 samples per trial. Here, we create a batch of 50 such trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:35:58.191991Z",
     "start_time": "2023-06-06T10:35:57.120752Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "X_torch = torch.randn(size=(50, 3, 200))  # size: (batch, in_chans, input_window_samples)\n",
    "y_torch = torch.randint(low=0, high=2, size=(50,))  # size: (batch), values: 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The to get our neural network, we simply have to instantiate the EEGNetv4 class with the right parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:35:59.062869Z",
     "start_time": "2023-06-06T10:35:58.192693Z"
    }
   },
   "outputs": [],
   "source": [
    "from braindecode.models import EEGNetv4\n",
    "\n",
    "module = EEGNetv4(in_chans=3, n_classes=2, input_window_samples=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can use the `forward` method of our neural network to get the predictions for our batch of trials:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:35:59.121316Z",
     "start_time": "2023-06-06T10:35:59.063374Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape = torch.Size([50, 2])\n"
     ]
    }
   ],
   "source": [
    "y_pred = module(X_torch)\n",
    "print('y_pred.shape =', y_pred.shape)  # size: (batch, n_classes)\n",
    "# print(y_pred.exp().sum(dim=1)) # y_pred are log-probabilities, so the exp of the outputs sum to 1 for each trial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network predicts the log-probability for each class, so we will have to use a negative log-likelihood loss to train it on classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Training a pytorch model\n",
    "\n",
    "Now that we have our neural network, we can train it on our fake data. Multiple methods exist to train Pytorch models. Under the hood, they all rely on pytorch, but they allow to reduce the amount of boilerplate code needed to train a model.\n",
    "\n",
    "#### Option 1 - Pure Pytorch training\n",
    "\n",
    "The first option at out disposal is to use pure Pytorch. For that, we need to first define an optimizer and a loss function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:35:59.127081Z",
     "start_time": "2023-06-06T10:35:59.122004Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "from torch import nn\n",
    "\n",
    "torch_module = deepcopy(module)  # we copy the architecture instantiated earlier\n",
    "optimizer = torch.optim.SGD(params=torch_module.parameters(), lr=0.001)\n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, the training loop is as follows:\n",
    "1. First, compute the predictions of the model on the input data;\n",
    "2. Then, compute the loss between the predictions and the targets;\n",
    "3. Then, compute the gradients of the loss with respect to the model parameters;\n",
    "4. Finally, update the model parameters according to the gradients and using the optimizer.\n",
    "\n",
    "This translates into the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.086955Z",
     "start_time": "2023-06-06T10:35:59.132047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "epoch 2\n",
      "epoch 3\n",
      "epoch 4\n",
      "epoch 5\n",
      "epoch 6\n",
      "epoch 7\n",
      "epoch 8\n",
      "epoch 9\n",
      "epoch 10\n"
     ]
    }
   ],
   "source": [
    "torch_module.train()\n",
    "for epoch in range(1, 11):\n",
    "    print('epoch', epoch)\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = torch_module(X_torch)\n",
    "    loss = criterion(y_pred, y_torch)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Training using Skorch\n",
    "\n",
    "The second option is to use the [Skorch](https://skorch.readthedocs.io/en/stable/) library. This library will take care of some of the boilerplate code for us but it also allows us to use Pytorch models as if they were scikit-learn models. This means that we can use them in scikit-learn pipelines, grid-searches, etc.\n",
    "\n",
    "For this, we simply have to wrapp our Pytorch model in a `skorch.NeuralNetClassifier` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.090420Z",
     "start_time": "2023-06-06T10:36:00.087392Z"
    }
   },
   "outputs": [],
   "source": [
    "from braindecode import EEGClassifier  # EEGClassifier is a subclass of skorch.NeuralNetClassifier\n",
    "\n",
    "skorch_module = deepcopy(module)  # we copy the architecture instantiated earlier\n",
    "skorch_classifier = EEGClassifier(skorch_module, max_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, as any scikit-learn model, we can use simple numpy arrays as training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.093548Z",
     "start_time": "2023-06-06T10:36:00.091523Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_np = np.random.randn(50, 3, 200)  # size: (batch, in_chans, input_window_samples)\n",
    "y_np = np.random.randint(low=0, high=2, size=50)  # size: (batch), values: 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can train our model in one line, using the `fit` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.174472Z",
     "start_time": "2023-06-06T10:36:00.094757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "      1        \u001B[36m0.6954\u001B[0m  0.0082\n",
      "      2        0.6954  0.0062\n",
      "      3        0.6954  0.0057\n",
      "      4        0.6954  0.0058\n",
      "      5        0.6954  0.0062\n",
      "      6        0.6954  0.0059\n",
      "      7        0.6954  0.0057\n",
      "      8        0.6954  0.0069\n",
      "      9        0.6954  0.0061\n",
      "     10        0.6954  0.0052\n"
     ]
    }
   ],
   "source": [
    "_ = skorch_classifier.fit(X_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Among the boilerplate code that Skorch handles for us, we can see that it automatically logs the epoch number, the validation loss, and the duration of the epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 3 - Other libraries\n",
    "Skorch is not the only library you can use to handle the boilerplate code for training Pytorch models. The other options include:\n",
    "- [Lightning](https://www.pytorchlightning.ai/);\n",
    "- [Accelerate](https://huggingface.co/docs/accelerate/index) from HuggingFace;\n",
    "- [Ignite](https://pytorch.org/ignite/) from Pytorch.\n",
    "\n",
    "Those libraries are particularly relevant when training models on GPUs, TPUs, or in a distributed manner because they can automatically place the data and model on the right device and distribute the computations. They also provide more advanced features such as automatic mixed-precision training, gradient accumulation, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Sharing models on HuggingFace Hub\n",
    "The [HuggingFace Hub](https://huggingface.co/) is a platform that allows to share and download pre-trained models. Uploading models to Hugging Face Hub can be done in two steps: you first have the save the pre-trained weights  or your models on your local machine (i.e. in a file), then you can upload those files containing those files to the Hub.\n",
    "\n",
    "For this, we will first create a temporary local directory in order to not pollute our current directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.174682Z",
     "start_time": "2023-06-06T10:36:00.167437Z"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from tempfile import mkdtemp\n",
    "\n",
    "save_dir = Path(mkdtemp())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can save the pre-trained models in this temporary folder. Here we both save the weights of the Pytorch model and of the Skorch model, but they are independant of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:00.180721Z",
     "start_time": "2023-06-06T10:36:00.173992Z"
    }
   },
   "outputs": [],
   "source": [
    "skorch_classifier.save_params(\n",
    "    f_params=save_dir / 'skorch_params.pkl',\n",
    "    f_optimizer=save_dir / 'skorch_opt.pkl',\n",
    "    f_history=save_dir / 'skorch_history.json',\n",
    ")\n",
    "torch.save(torch_module.state_dict(), save_dir / 'torch_params.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can upload all the files in the temporary folder using the command `huggingface_hub.upload_folder`. Those files will be uploaded to the repository [`PierreGtch/EEGNetv4`](https://huggingface.co/PierreGtch/EEGNetv4) that also contain the pre-trained models presented at the 10<sup>th</sup> BCI Meeting (c.f. [poster](https://neurotechlab.socsci.ru.nl/resources/pretrained_imagery_models/)). In this repository, we put them in the folder named `toy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:02.260958Z",
     "start_time": "2023-06-06T10:36:00.176938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "torch_params.pkl:   0%|          | 0.00/12.4k [00:00<?, ?B/s]\n",
      "\n",
      "torch_params.pkl: 100%|██████████| 12.4k/12.4k [00:00<00:00, 33.6kB/s]\n",
      "\n",
      "torch_params.pkl: 100%|██████████| 12.4k/12.4k [00:00<00:00, 16.3kB/s]]\u001B[A\u001B[A\n",
      "skorch_params.pkl: 100%|██████████| 12.4k/12.4k [00:00<00:00, 15.8kB/s]\n",
      "\n",
      "Upload 2 LFS files: 100%|██████████| 2/2 [00:01<00:00,  1.98it/s]\u001B[A\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import upload_folder\n",
    "\n",
    "_ = upload_folder(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    folder_path=save_dir,\n",
    "    path_in_repo='toy',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can remove our temporary local folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:02.263484Z",
     "start_time": "2023-06-06T10:36:02.260570Z"
    }
   },
   "outputs": [],
   "source": [
    "from shutil import rmtree\n",
    "\n",
    "rmtree(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Re-using pre-trained neural networks\n",
    "\n",
    "This part is focused on re-using pre-trained BCI models. It is designed as a stand-alone, so there will be redundant imports with the previous part.\n",
    "\n",
    "### 2.1. Loading models from HuggingFace Hub\n",
    "\n",
    "The first step to re-using a pre-trained model is to download it from the HuggingFace Hub. For this, we will use the function `huggingface_hub.hf_hub_download`. This function takes as input the repository ID and the name of the file to download. It returns the local path to the downloaded file. The nice thing is that if this file is already present on your local machine, it will not be downloaded again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:03.891245Z",
     "start_time": "2023-06-06T10:36:02.264884Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading torch_params.pkl: 100%|██████████| 12.4k/12.4k [00:00<00:00, 20.4MB/s]\n",
      "Downloading skorch_params.pkl: 100%|██████████| 12.4k/12.4k [00:00<00:00, 64.6MB/s]\n",
      "Downloading (…)/skorch_history.json: 100%|██████████| 2.22k/2.22k [00:00<00:00, 25.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "file_names = dict(\n",
    "    torch='torch_params.pkl',\n",
    "    f_params='skorch_params.pkl',\n",
    "    f_optimizer='skorch_opt.pkl',\n",
    "    f_history='skorch_history.json',\n",
    ")\n",
    "local_paths = {\n",
    "    k: hf_hub_download(\n",
    "        repo_id='PierreGtch/EEGNetv4',\n",
    "        filename='toy/' + name,\n",
    "    )\n",
    "    for k, name in file_names.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have downloaded and collected local paths to the pre-trained weights of our models from Part 1, we can load then in memory. For this, we first have to instantiate the model architecture, then we can load the weights using the `load_state_dict` method (for Pytorch) or the `load_params` method (for Skorch):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:03.908858Z",
     "start_time": "2023-06-06T10:36:03.896234Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.models import EEGNetv4\n",
    "\n",
    "# load the pure pytorch module:\n",
    "torch_module = EEGNetv4(in_chans=3, n_classes=2, input_window_samples=200)\n",
    "torch_module.load_state_dict(torch.load(local_paths['torch']))\n",
    "\n",
    "# load the pure pytorch module:\n",
    "skorch_module = EEGNetv4(in_chans=3, n_classes=2, input_window_samples=200)\n",
    "skorch_classifier = EEGClassifier(skorch_module, max_epochs=5)\n",
    "skorch_classifier.initialize()\n",
    "skorch_classifier.load_params(\n",
    "    f_params=local_paths['f_params'],\n",
    "    f_optimizer=local_paths['f_optimizer'],\n",
    "    f_history=local_paths['f_history'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Re-using a pre-trained neural network\n",
    "\n",
    "Once a pre-trained model is loaded, we can use it in different ways.\n",
    "\n",
    "#### Option 1 - Simple prediction\n",
    "\n",
    "The first option is to simply use the model to make predictions on new data. For this, we will first create again some fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:03.917608Z",
     "start_time": "2023-06-06T10:36:03.909773Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_np = np.random.randn(20, 3, 200)  # size: (batch, in_chans, input_window_samples)\n",
    "y_np = np.random.randint(low=0, high=2, size=20)  # size: (batch), values: 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, like any other Scikit-learn estimator, we can use the `predict` method of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:03.958203Z",
     "start_time": "2023-06-06T10:36:03.913129Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_classifier.predict(X_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or its `score` method to get the accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.012514Z",
     "start_time": "2023-06-06T10:36:03.959206Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skorch_classifier.score(X_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Option 2 - Fine-tuning using Skorch\n",
    "\n",
    "We also have the possibility to fine-tune the model using Skorch. For this, we will use the `partial_fit` method of the Skorch classifier. Here, we will use it to train the model for a few additional epochs on our fake data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.023641Z",
     "start_time": "2023-06-06T10:36:04.012306Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    valid_loss     dur\n",
      "-------  ------------  ------\n",
      "     11        \u001B[36m0.6920\u001B[0m  0.0034\n",
      "     12        0.6920  0.0028\n",
      "     13        0.6920  0.0028\n",
      "     14        0.6920  0.0034\n",
      "     15        0.6920  0.0024\n"
     ]
    }
   ],
   "source": [
    "_ = skorch_classifier.partial_fit(X_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " As you can see, the training did not start from scratch, it started at the 10<sup>th</sup> epoch, where the model was saved in Part 1. Please also note that teh state of the optimizer was also restored. This is particularly useful for optimizer with learnable parameters, such as Adam.\n",
    "\n",
    "#### Option 3 - Frozen embedding in a Scikit-learn pipeline\n",
    "\n",
    "Finally, the method we used to obtain the results presented ath the 10<sup>th</sup> BCI Meeting (c.f. [poster](https://neurotechlab.socsci.ru.nl/resources/pretrained_imagery_models/)): using the pre-trained model as a frozen feature extractor in a Scikit-learn classification pipeline. For this, we first have to get a frozen feature extractor from our classification neural network. To do that, we define two function: one that discards the classification layers and only keep the embedding part of the model, and one that freezes the model to avoid accumulating gradients unnecessarily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.030819Z",
     "start_time": "2023-06-06T10:36:04.027119Z"
    }
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "def remove_clf_layers(model: nn.Sequential):\n",
    "    \"\"\"\n",
    "    Remove the classification layers from braindecode models.\n",
    "    Tested on EEGNetv4, Deep4Net (i.e. DeepConvNet), and EEGResNet.\n",
    "    \"\"\"\n",
    "    new_layers = []\n",
    "    for name, layer in model.named_children():\n",
    "        if 'classif' in name:\n",
    "            continue\n",
    "        if 'softmax' in name:\n",
    "            continue\n",
    "        new_layers.append((name, layer))\n",
    "    return nn.Sequential(OrderedDict(new_layers))\n",
    "\n",
    "\n",
    "def freeze_model(model):\n",
    "    model.eval()\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    return model\n",
    "\n",
    "\n",
    "embedding = freeze_model(remove_clf_layers(torch_module)).double()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a frozen pytorch model to act as frozen embedding function, we want to integrate it in a Scikit-learn pipeline. For this, we need to wrap it in a `sklearn.base.TransformerMixin`. Unfortunately, Skorch does not implement this kind of estimators, so we have to define it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.049508Z",
     "start_time": "2023-06-06T10:36:04.031236Z"
    }
   },
   "outputs": [],
   "source": [
    "from skorch import NeuralNet\n",
    "from skorch.utils import to_numpy\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class FrozenNeuralNetTransformer(NeuralNet, TransformerMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            *args,\n",
    "            criterion=nn.MSELoss,  # should be unused\n",
    "            unique_name=None,  # needed for a unique digest in MOABB\n",
    "            **kwargs\n",
    "    ):\n",
    "        super().__init__(\n",
    "            *args,\n",
    "            criterion=criterion,\n",
    "            **kwargs\n",
    "        )\n",
    "        self.initialize()\n",
    "        self.unique_name = unique_name\n",
    "\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self  # do nothing\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = self.infer(X)\n",
    "        return to_numpy(X)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return super().__repr__() + self.unique_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, we define a function that flattens all the dimensions of its input except for the first one (i.e. the batch dimension). This way, we will be able to pass those frozen features to Scikit-learn classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.049759Z",
     "start_time": "2023-06-06T10:36:04.034297Z"
    }
   },
   "outputs": [],
   "source": [
    "def flatten_batched(X):\n",
    "    return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now, we can combine all the pieces together into a Scikit-learn pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.081378Z",
     "start_time": "2023-06-06T10:36:04.036886Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('embedding', FrozenNeuralNetTransformer(embedding)),\n",
    "    ('flatten', FunctionTransformer(flatten_batched)),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if you call the `fit` method of this pipeline, only the logistic regression will be trained, the embedding will remain frozen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.097577Z",
     "start_time": "2023-06-06T10:36:04.081091Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = sklearn_pipeline.fit(X_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. Benchmarking with MOABB\n",
    "\n",
    "Now that we know how to integrate our pre-trained models in Scikit-learn pipelines and train them, we can benchmark them using the [MOABB](https://neurotechx.github.io/moabb/index.html) library. In order to get interesting results, we will load a model that was properly trained on a real dataset. In particular, we will load the model that was pre-trained on the dataset [Lee2019_MI](https://neurotechx.github.io/moabb/generated/moabb.datasets.Lee2019_MI.html) because it showed good transfer results for the left hand vs right hand classification task. Here, we simply repeat what was done in sections 2.1. and 2.2. option 3, but with the real model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:04.362758Z",
     "start_time": "2023-06-06T10:36:04.099972Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# download the model from the hub:\n",
    "path_kwargs = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/kwargs.pkl',\n",
    ")\n",
    "path_params = hf_hub_download(\n",
    "    repo_id='PierreGtch/EEGNetv4',\n",
    "    filename='EEGNetv4_Lee2019_MI/model-params.pkl',\n",
    ")\n",
    "with open(path_kwargs, 'rb') as f:\n",
    "    kwargs = pickle.load(f)\n",
    "module_cls = kwargs['module_cls']\n",
    "module_kwargs = kwargs['module_kwargs']\n",
    "\n",
    "# load the model with pre-trained weights:\n",
    "torch_module = module_cls(**module_kwargs)\n",
    "torch_module.load_state_dict(torch.load(path_params, map_location='cpu'))\n",
    "embedding = freeze_model(remove_clf_layers(torch_module)).double()\n",
    "\n",
    "# Integrate the model in a Scikit-learn pipeline:\n",
    "sklearn_pipeline = Pipeline([\n",
    "    ('embedding', FrozenNeuralNetTransformer(embedding, unique_name='pretrained_Lee2019')),\n",
    "    ('flatten', FunctionTransformer(flatten_batched)),\n",
    "    ('classifier', LogisticRegression()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To benchmark a pipeline with MOABB, we have to define three components:\n",
    "1. The paradigm, i.e. the pre-processing and epoching steps that will be applied to the data;\n",
    "2. The datasets on which the pipeline will be evaluated;\n",
    "3. And the evaluation procedure, which can be within-session, cross-session or cross-subject.\n",
    "\n",
    "We will use the same paradigm and evaluation parameters as those we used to obtain the results in the [poster](https://neurotechlab.socsci.ru.nl/resources/pretrained_imagery_models/). However, we only test on the [Zhou2017](https://neurotechx.github.io/moabb/generated/moabb.datasets.Zhou2016.html) dataset because it is relatively small and lightweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:05.022711Z",
     "start_time": "2023-06-06T10:36:04.364332Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow not install, you could not use those pipelines\n"
     ]
    }
   ],
   "source": [
    "from moabb.paradigms import MotorImagery\n",
    "from moabb.datasets import Zhou2016\n",
    "from moabb.evaluations import WithinSessionEvaluation\n",
    "\n",
    "paradigm = MotorImagery(\n",
    "    channels=['C3', 'Cz', 'C4'],  # Same as the ones used to pre-train the embedding\n",
    "    events=['left_hand', 'right_hand', 'feet'],\n",
    "    n_classes=3,\n",
    "    fmin=0.5,\n",
    "    fmax=40,\n",
    "    tmin=0,\n",
    "    tmax=3,\n",
    "    resample=128,\n",
    ")\n",
    "datasets = [Zhou2016()]\n",
    "evaluation = WithinSessionEvaluation(\n",
    "    paradigm=paradigm,\n",
    "    datasets=datasets,\n",
    "    overwrite=True,\n",
    "    suffix='demo',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the paradigm, datasets and evaluation procedure are defined, benchmarking the pipeline is done in one line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:11.542965Z",
     "start_time": "2023-06-06T10:36:05.023497Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Zhou 2016-WithinSession:   0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 305029  =      0.000 ...  1220.116 secs...\n",
      "Reading 0 ... 430479  =      0.000 ...  1721.916 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 252599  =      0.000 ...  1010.396 secs...\n",
      "Reading 0 ... 296649  =      0.000 ...  1186.596 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 233249  =      0.000 ...   932.996 secs...\n",
      "Reading 0 ... 226219  =      0.000 ...   904.876 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "Zhou 2016-WithinSession:  25%|██▌       | 1/4 [00:01<00:05,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 227539  =      0.000 ...   910.156 secs...\n",
      "Reading 0 ... 216079  =      0.000 ...   864.316 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 213939  =      0.000 ...   855.756 secs...\n",
      "Reading 0 ... 175269  =      0.000 ...   701.076 secs...\n",
      "Reading 0 ... 213209  =      0.000 ...   852.836 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 217659  =      0.000 ...   870.636 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "Zhou 2016-WithinSession:  50%|█████     | 2/4 [00:03<00:03,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 219849  =      0.000 ...   879.396 secs...\n",
      "Reading 0 ... 216709  =      0.000 ...   866.836 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 226609  =      0.000 ...   906.436 secs...\n",
      "Reading 0 ... 266929  =      0.000 ...  1067.716 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 227989  =      0.000 ...   911.956 secs...\n",
      "Reading 0 ... 222459  =      0.000 ...   889.836 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "Zhou 2016-WithinSession:  75%|███████▌  | 3/4 [00:04<00:01,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 181339  =      0.000 ...   725.356 secs...\n",
      "Reading 0 ... 217139  =      0.000 ...   868.556 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 215399  =      0.000 ...   861.596 secs...\n",
      "Reading 0 ... 212209  =      0.000 ...   848.836 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning:   Could not parse meas date from the header. Setting to None.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 209799  =      0.000 ...   839.196 secs...\n",
      "Reading 0 ... 217109  =      0.000 ...   868.436 secs...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "/Users/Pierre.Guetschel/miniforge3/envs/motor_embedding_benchmark/lib/python3.10/site-packages/moabb/datasets/Zhou2016.py:111: RuntimeWarning: Could not define the number of bytes automatically. Defaulting to 2.\n",
      "  raw = read_raw_cnt(fname, preload=True, eog=[\"VEOU\", \"VEOL\"])\n",
      "Zhou 2016-WithinSession: 100%|██████████| 4/4 [00:06<00:00,  1.62s/it]\n"
     ]
    }
   ],
   "source": [
    "results = evaluation.process(pipelines=dict(demo_pipeline=sklearn_pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the results are returned as a [pandas dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-06T10:36:11.543215Z",
     "start_time": "2023-06-06T10:36:11.529367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>time</th>\n",
       "      <th>samples</th>\n",
       "      <th>subject</th>\n",
       "      <th>session</th>\n",
       "      <th>channels</th>\n",
       "      <th>n_sessions</th>\n",
       "      <th>dataset</th>\n",
       "      <th>pipeline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.798730</td>\n",
       "      <td>0.055640</td>\n",
       "      <td>179.0</td>\n",
       "      <td>1</td>\n",
       "      <td>session_0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.038590</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>session_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.806667</td>\n",
       "      <td>0.039696</td>\n",
       "      <td>150.0</td>\n",
       "      <td>1</td>\n",
       "      <td>session_2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.039505</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>session_0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.035550</td>\n",
       "      <td>135.0</td>\n",
       "      <td>2</td>\n",
       "      <td>session_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.039898</td>\n",
       "      <td>150.0</td>\n",
       "      <td>2</td>\n",
       "      <td>session_2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.043984</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>session_0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.721936</td>\n",
       "      <td>0.043639</td>\n",
       "      <td>151.0</td>\n",
       "      <td>3</td>\n",
       "      <td>session_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.043179</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3</td>\n",
       "      <td>session_2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.038144</td>\n",
       "      <td>135.0</td>\n",
       "      <td>4</td>\n",
       "      <td>session_0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.793333</td>\n",
       "      <td>0.043317</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>session_1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.813333</td>\n",
       "      <td>0.041490</td>\n",
       "      <td>150.0</td>\n",
       "      <td>4</td>\n",
       "      <td>session_2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Zhou 2016</td>\n",
       "      <td>demo_pipeline</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score      time  samples subject    session  channels  n_sessions  \\\n",
       "0   0.798730  0.055640    179.0       1  session_0         3           3   \n",
       "1   0.800000  0.038590    150.0       1  session_1         3           3   \n",
       "2   0.806667  0.039696    150.0       1  session_2         3           3   \n",
       "3   0.746667  0.039505    150.0       2  session_0         3           3   \n",
       "4   0.785185  0.035550    135.0       2  session_1         3           3   \n",
       "5   0.766667  0.039898    150.0       2  session_2         3           3   \n",
       "6   0.766667  0.043984    150.0       3  session_0         3           3   \n",
       "7   0.721936  0.043639    151.0       3  session_1         3           3   \n",
       "8   0.700000  0.043179    150.0       3  session_2         3           3   \n",
       "9   0.851852  0.038144    135.0       4  session_0         3           3   \n",
       "10  0.793333  0.043317    150.0       4  session_1         3           3   \n",
       "11  0.813333  0.041490    150.0       4  session_2         3           3   \n",
       "\n",
       "      dataset       pipeline  \n",
       "0   Zhou 2016  demo_pipeline  \n",
       "1   Zhou 2016  demo_pipeline  \n",
       "2   Zhou 2016  demo_pipeline  \n",
       "3   Zhou 2016  demo_pipeline  \n",
       "4   Zhou 2016  demo_pipeline  \n",
       "5   Zhou 2016  demo_pipeline  \n",
       "6   Zhou 2016  demo_pipeline  \n",
       "7   Zhou 2016  demo_pipeline  \n",
       "8   Zhou 2016  demo_pipeline  \n",
       "9   Zhou 2016  demo_pipeline  \n",
       "10  Zhou 2016  demo_pipeline  \n",
       "11  Zhou 2016  demo_pipeline  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
